{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import bregnn.ffwd as ffwd \n",
    "import bregnn.kin as kin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bregnn.io' from '/users/musella/HHbbgg_ETH/bregression/notebooks/bregnn/io.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bregnn.io as io\n",
    "reload(io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "jetvars = ['recoJet2p5Energy',\n",
    "           'recoJet2p5Pt',\n",
    "           'recoJet2p5Eta',\n",
    "           'recoJet2p5Phi',\n",
    "           'recoJet2p5Pujetidmva',\n",
    "           'recoJet2p5Px',\n",
    "           'recoJet2p5Py',\n",
    "           'recoJet2p5Pz']\n",
    "\n",
    "jets = [  [var+ijet for var in jetvars ] for ijet in ['0','1','2','3','4','5']  ]\n",
    "\n",
    "linv = ['recoJet2p5P0P1',\n",
    "        'recoJet2p5P0P2',\n",
    "        'recoJet2p5P0P3',\n",
    "        'recoJet2p5P0P4',\n",
    "        'recoJet2p5P0P5',\n",
    "        'recoJet2p5P1P2',\n",
    "        'recoJet2p5P1P3',\n",
    "        'recoJet2p5P1P4',\n",
    "        'recoJet2p5P1P5',\n",
    "        'recoJet2p5P2P3',\n",
    "        'recoJet2p5P2P4',\n",
    "        'recoJet2p5P2P5',\n",
    "        'recoJet2p5P3P4',\n",
    "        'recoJet2p5P3P5',\n",
    "        'recoJet2p5P4P5',\n",
    "        'recoJet2p5Mass20',\n",
    "        'recoJet2p5Mass21',\n",
    "        'recoJet2p5Mass22',\n",
    "        'recoJet2p5Mass23',\n",
    "        'recoJet2p5Mass24',\n",
    "        'recoJet2p5Mass25']\n",
    "\n",
    "lep = ['recoPt','recoEta','recoPhi','recoPx', 'recoPy' ]\n",
    "\n",
    "met = ['recoMETAllPt','recoMETAllPhi','recoMETAllPx','recoMETAllPy']\n",
    "\n",
    "target = 'genJet2p5Mass201'\n",
    "\n",
    "from functools import reduce\n",
    "alljets = reduce(lambda x,y: x+y, jets)\n",
    "\n",
    "columns = alljets+lep+met+linv+[target,'processIndex','genNjets2p5','recoNjets2p5','recoJet2p5Mass201']\n",
    "base_dir = os.environ['SCRATCH'] + '/kinfit'\n",
    "\n",
    "data = io.read_data(base_dir+'/kin_fit_input.hd5', columns = columns )\n",
    "\n",
    "# for var in linv+[target]:\n",
    "#     data[var] /= data['recoJet2p5Mass201']\n",
    "\n",
    "data[target] /= data['recoJet2p5Mass201']\n",
    "data[target] = np.sqrt(data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = data[(data.processIndex == 11) & (data.genNjets2p5 >= 2) & (data.recoNjets2p5 >= 2) ]#  & (data.recoPt > 100.) ]\n",
    "\n",
    "\n",
    "# data[linv] = data[linv].fillna(0.)\n",
    "\n",
    "\n",
    "\n",
    "# data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reload(ffwd)\n",
    "\n",
    "# X0 = data[ linv ].values\n",
    "# y0 = np.sqrt( data['recoJet2p5Mass201'].values )\n",
    "\n",
    "# y0 -= np.median(y0)\n",
    "# y0 /= y0.std()\n",
    "\n",
    "# X0 -= np.median(X0)\n",
    "# X0 /= X0.std()\n",
    "\n",
    "# reload(ffwd)\n",
    "# mreg = ffwd.FFWDRegression('mreg',X0.shape[1:],do_bn0=False,loss='mse',layers=[128]*3+[64,32],dropout=None)\n",
    "\n",
    "# mmodel = mreg(True)\n",
    "\n",
    "# mmodel.fit(X0,y0,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995862 0.736426\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "reload(ffwd)\n",
    "reload(kin)\n",
    "\n",
    "# features = alljets+lep+met+linv\n",
    "# X = data[features].values\n",
    "\n",
    "Xjets = np.concatenate([ data[jet].values.reshape(data.shape[0],1,-1) for jet in jets ],axis=-2)\n",
    "Xev = data[lep+met].values\n",
    "Xlinv = data[linv].values\n",
    "\n",
    "Xjets -= np.median(Xjets,axis=1,keepdims=True)\n",
    "Xjets /= np.std(Xjets,axis=1,keepdims=True)\n",
    "\n",
    "Xev -= np.median(Xev,axis=1,keepdims=True)\n",
    "Xev /= np.std(Xev,axis=1,keepdims=True)\n",
    "\n",
    "Xlinv -= np.median(Xlinv,axis=1,keepdims=True)\n",
    "Xlinv /= np.std(Xlinv,axis=1,keepdims=True)\n",
    "\n",
    "\n",
    "y = data[ [target] ].values\n",
    "\n",
    "y_mean = np.median(y)#.mean()\n",
    "iq = np.percentile(y,[25,70.])\n",
    "# print(iq)\n",
    "\n",
    "y -= y_mean\n",
    "\n",
    "y_std = y.std() #iq[1] - iq[0]  #y.std()\n",
    "y /= y_std\n",
    "\n",
    "\n",
    "\n",
    "print(y_mean,y_std)\n",
    "\n",
    "# reg = kin.KinRegression('kin',Xjets.shape[1:],Xev.shape[1:],Xlinv.shape[1:],\n",
    "#                         loss='HuberLoss',loss_params=dict(delta=0.4),#loss='mae',\n",
    "#                         jets_layers=[64]*5,ev_layers=[32]*5,fc1_layers=[512,256,128],\n",
    "#                         fc2_layers=[128]*3+[64,32],\n",
    "#                         #noise=0.5,\n",
    "#                         dropout=0.5,optimizer_params=dict(lr=5.e-5))#,const_output_biases=np.array([y_mean,y_std/y_mean]))\n",
    "\n",
    "reg = kin.KinRegression('kin',Xjets.shape[1:],Xev.shape[1:],Xlinv.shape[1:],\n",
    "                        # loss='HuberLoss',loss_params=dict(delta=0.4),#loss='mae',\n",
    "                        loss='HybridLoss',\n",
    "                        do_bn0=True,\n",
    "                        jets_layers=[64]*3,jets_activations=\"tanh\",ev_layers=[],fc1_layers=[],\n",
    "                        fc2_layers=[512]*4+[256,128,64,32],\n",
    "                        noise=0.5,\n",
    "                        dropout=0.5,optimizer_params=dict(lr=5.e-4))#,const_output_biases=np.array([y_mean,y_std/y_mean]))\n",
    "\n",
    "# reg = ffwd.FFWDRegression('ffw',X.shape[1:],\n",
    "#                          #loss='HuberLoss',loss_params=dict(delta=0.4),\n",
    "#                           loss='HybridLoss',\n",
    "#                           layers=[512]*4+[256,128,64,32],#activations='tanh',\n",
    "#                           noise=0.5,\n",
    "#                           dropout=0.5,optimizer_params=dict(lr=5.e-4))\n",
    "# reg = ffwd.FFWDRegression('ffwd',X.shape[1:],loss='mse')#const_output_biases=np.array([y_mean]),loss='mse')\n",
    "\n",
    "model = reg(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = data['recoJet2p5Mass201']\n",
    "# y0 -= y_mean\n",
    "# y0 /= y_std\n",
    "# print(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAJPCAYAAAAe4/KiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b0cab7969e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y,range=[-2,2],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.genNjets2p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "kin_ev_inp (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_inp (InputLayer)       (None, 6, 8)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "kin_ev_nb0 (BatchNormalization) (None, 9)            36          kin_ev_inp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_nb0 (BatchNormalizatio (None, 6, 8)         32          kin_jets_inp[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_ev_jets_rpt (RepeatVector)  (None, 6, 9)         0           kin_ev_nb0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_concat (Concatenate)   (None, 6, 17)        0           kin_jets_nb0[0][0]               \n",
      "                                                                 kin_ev_jets_rpt[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_dense1 (Conv1D)        (None, 6, 64)        1088        kin_jets_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_bn1 (BatchNormalizatio (None, 6, 64)        256         kin_jets_dense1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_noi1 (GaussianNoise)   (None, 6, 64)        0           kin_jets_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_do1 (Dropout)          (None, 6, 64)        0           kin_jets_noi1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_act1_tanh (Activation) (None, 6, 64)        0           kin_jets_do1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_dense2 (Conv1D)        (None, 6, 64)        4096        kin_jets_act1_tanh[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_bn2 (BatchNormalizatio (None, 6, 64)        256         kin_jets_dense2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_noi2 (GaussianNoise)   (None, 6, 64)        0           kin_jets_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_do2 (Dropout)          (None, 6, 64)        0           kin_jets_noi2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_act2_tanh (Activation) (None, 6, 64)        0           kin_jets_do2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_dense3 (Conv1D)        (None, 6, 64)        4096        kin_jets_act2_tanh[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_bn3 (BatchNormalizatio (None, 6, 64)        256         kin_jets_dense3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_noi3 (GaussianNoise)   (None, 6, 64)        0           kin_jets_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_do3 (Dropout)          (None, 6, 64)        0           kin_jets_noi3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_act3_tanh (Activation) (None, 6, 64)        0           kin_jets_do3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_flt (Flatten)          (None, 384)          0           kin_jets_act3_tanh[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_inp_flt (Flatten)      (None, 48)           0           kin_jets_nb0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_linv_inp (InputLayer)       (None, 21)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "kin_jets_out_concat (Concatenat (None, 432)          0           kin_jets_flt[0][0]               \n",
      "                                                                 kin_jets_inp_flt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "kin_linb_nb0 (BatchNormalizatio (None, 21)           84          kin_linv_inp[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_concat (Concatenate)        (None, 462)          0           kin_jets_out_concat[0][0]        \n",
      "                                                                 kin_ev_nb0[0][0]                 \n",
      "                                                                 kin_linb_nb0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense1 (Dense)              (None, 512)          236544      kin_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn1 (BatchNormalization)    (None, 512)          2048        kin_dense1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi1 (GaussianNoise)        (None, 512)          0           kin_bn1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do1 (Dropout)               (None, 512)          0           kin_noi1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act1_lrelu (LeakyReLU)      (None, 512)          0           kin_do1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense2 (Dense)              (None, 512)          262144      kin_act1_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn2 (BatchNormalization)    (None, 512)          2048        kin_dense2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi2 (GaussianNoise)        (None, 512)          0           kin_bn2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do2 (Dropout)               (None, 512)          0           kin_noi2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act2_lrelu (LeakyReLU)      (None, 512)          0           kin_do2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense3 (Dense)              (None, 512)          262144      kin_act2_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn3 (BatchNormalization)    (None, 512)          2048        kin_dense3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi3 (GaussianNoise)        (None, 512)          0           kin_bn3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do3 (Dropout)               (None, 512)          0           kin_noi3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act3_lrelu (LeakyReLU)      (None, 512)          0           kin_do3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense4 (Dense)              (None, 512)          262144      kin_act3_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn4 (BatchNormalization)    (None, 512)          2048        kin_dense4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi4 (GaussianNoise)        (None, 512)          0           kin_bn4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do4 (Dropout)               (None, 512)          0           kin_noi4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act4_lrelu (LeakyReLU)      (None, 512)          0           kin_do4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense5 (Dense)              (None, 256)          131072      kin_act4_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn5 (BatchNormalization)    (None, 256)          1024        kin_dense5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi5 (GaussianNoise)        (None, 256)          0           kin_bn5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do5 (Dropout)               (None, 256)          0           kin_noi5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act5_lrelu (LeakyReLU)      (None, 256)          0           kin_do5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense6 (Dense)              (None, 128)          32768       kin_act5_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn6 (BatchNormalization)    (None, 128)          512         kin_dense6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi6 (GaussianNoise)        (None, 128)          0           kin_bn6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do6 (Dropout)               (None, 128)          0           kin_noi6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act6_lrelu (LeakyReLU)      (None, 128)          0           kin_do6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense7 (Dense)              (None, 64)           8192        kin_act6_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn7 (BatchNormalization)    (None, 64)           256         kin_dense7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi7 (GaussianNoise)        (None, 64)           0           kin_bn7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do7 (Dropout)               (None, 64)           0           kin_noi7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act7_lrelu (LeakyReLU)      (None, 64)           0           kin_do7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_dense8 (Dense)              (None, 32)           2048        kin_act7_lrelu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "kin_bn8 (BatchNormalization)    (None, 32)           128         kin_dense8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "kin_noi8 (GaussianNoise)        (None, 32)           0           kin_bn8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_do8 (Dropout)               (None, 32)           0           kin_noi8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "kin_act8_lrelu (LeakyReLU)      (None, 32)           0           kin_do8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "kin_out (Dense)                 (None, 3)            99          kin_act8_lrelu[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,217,467\n",
      "Trainable params: 1,211,951\n",
      "Non-trainable params: 5,516\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import bregnn.losses as losses\n",
    "\n",
    "# opt = Adam(lr=1e-4)\n",
    "\n",
    "# reload(losses)\n",
    "\n",
    "# model.compile(optimizer=opt,loss=losses.gauss_nll)\n",
    "# # model.compile(optimizer=opt,loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xjets_train,Xjets_valid,Xev_train,Xev_valid,Xlinv_train,Xlinv_valid,y_train,y_valid,y0_train,y0_valid = train_test_split(Xjets,Xev,Xlinv,y,y0,test_size=0.1,random_state=12345)\n",
    "X_train = [Xjets_train,Xev_train,Xlinv_train]\n",
    "X_valid = [Xjets_valid,Xev_valid,Xlinv_valid]\n",
    "# X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.05,random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38328 samples, validate on 4259 samples\n",
      "Epoch 1/200\n",
      "38328/38328 [==============================] - 12s 301us/step - loss: 1.1153 - mse0: 2.1584 - mae0: 0.9794 - r2_score0: -1.6939 - val_loss: 0.3364 - val_mse0: 0.9300 - val_mae0: 0.3178 - val_r2_score0: -0.0103\n",
      "Epoch 2/200\n",
      "38328/38328 [==============================] - 7s 196us/step - loss: 0.7406 - mse0: 1.4964 - mae0: 0.7138 - r2_score0: -0.7004 - val_loss: 0.3227 - val_mse0: 0.9403 - val_mae0: 0.3051 - val_r2_score0: -0.0213\n",
      "Epoch 3/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.5605 - mse0: 1.2512 - mae0: 0.5651 - r2_score0: -0.3533 - val_loss: 0.3171 - val_mse0: 0.9432 - val_mae0: 0.3057 - val_r2_score0: -0.0248\n",
      "Epoch 4/200\n",
      "38328/38328 [==============================] - 8s 206us/step - loss: 0.4520 - mse0: 1.1380 - mae0: 0.4673 - r2_score0: -0.1666 - val_loss: 0.3116 - val_mse0: 0.9413 - val_mae0: 0.3064 - val_r2_score0: -0.0242\n",
      "Epoch 5/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3886 - mse0: 1.0772 - mae0: 0.4059 - r2_score0: -0.0946 - val_loss: 0.3068 - val_mse0: 0.9421 - val_mae0: 0.3059 - val_r2_score0: -0.0246\n",
      "Epoch 6/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3552 - mse0: 1.0527 - mae0: 0.3728 - r2_score0: -0.0610 - val_loss: 0.3034 - val_mse0: 0.9407 - val_mae0: 0.3056 - val_r2_score0: -0.0223\n",
      "Epoch 7/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3382 - mse0: 1.0356 - mae0: 0.3542 - r2_score0: -0.0351 - val_loss: 0.3021 - val_mse0: 0.9397 - val_mae0: 0.3061 - val_r2_score0: -0.0213\n",
      "Epoch 8/200\n",
      "38328/38328 [==============================] - 8s 205us/step - loss: 0.3319 - mse0: 1.0316 - mae0: 0.3443 - r2_score0: -0.0271 - val_loss: 0.3015 - val_mse0: 0.9384 - val_mae0: 0.3063 - val_r2_score0: -0.0194\n",
      "Epoch 9/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3290 - mse0: 1.0266 - mae0: 0.3387 - r2_score0: -0.0199 - val_loss: 0.3013 - val_mse0: 0.9381 - val_mae0: 0.3064 - val_r2_score0: -0.0190\n",
      "Epoch 10/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3275 - mse0: 1.0246 - mae0: 0.3339 - r2_score0: -0.0183 - val_loss: 0.3011 - val_mse0: 0.9366 - val_mae0: 0.3072 - val_r2_score0: -0.0171\n",
      "Epoch 11/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3272 - mse0: 1.0239 - mae0: 0.3332 - r2_score0: -0.0173 - val_loss: 0.3010 - val_mse0: 0.9357 - val_mae0: 0.3077 - val_r2_score0: -0.0161\n",
      "Epoch 12/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3268 - mse0: 1.0233 - mae0: 0.3319 - r2_score0: -0.0161 - val_loss: 0.3010 - val_mse0: 0.9355 - val_mae0: 0.3079 - val_r2_score0: -0.0159\n",
      "Epoch 13/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3266 - mse0: 1.0219 - mae0: 0.3313 - r2_score0: -0.0148 - val_loss: 0.3009 - val_mse0: 0.9353 - val_mae0: 0.3079 - val_r2_score0: -0.0157\n",
      "Epoch 14/200\n",
      "38328/38328 [==============================] - 8s 202us/step - loss: 0.3266 - mse0: 1.0227 - mae0: 0.3307 - r2_score0: -0.0158 - val_loss: 0.3009 - val_mse0: 0.9344 - val_mae0: 0.3087 - val_r2_score0: -0.0146\n",
      "Epoch 15/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3264 - mse0: 1.0214 - mae0: 0.3311 - r2_score0: -0.0141 - val_loss: 0.3009 - val_mse0: 0.9347 - val_mae0: 0.3083 - val_r2_score0: -0.0150\n",
      "Epoch 16/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3265 - mse0: 1.0223 - mae0: 0.3306 - r2_score0: -0.0154 - val_loss: 0.3008 - val_mse0: 0.9341 - val_mae0: 0.3088 - val_r2_score0: -0.0143\n",
      "Epoch 17/200\n",
      "38328/38328 [==============================] - 8s 209us/step - loss: 0.3263 - mse0: 1.0213 - mae0: 0.3308 - r2_score0: -0.0140 - val_loss: 0.3008 - val_mse0: 0.9336 - val_mae0: 0.3092 - val_r2_score0: -0.0142\n",
      "Epoch 18/200\n",
      "38328/38328 [==============================] - 8s 209us/step - loss: 0.3264 - mse0: 1.0209 - mae0: 0.3312 - r2_score0: -0.0138 - val_loss: 0.3007 - val_mse0: 0.9337 - val_mae0: 0.3087 - val_r2_score0: -0.0140\n",
      "Epoch 19/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.3263 - mse0: 1.0212 - mae0: 0.3308 - r2_score0: -0.0138 - val_loss: 0.3007 - val_mse0: 0.9336 - val_mae0: 0.3086 - val_r2_score0: -0.0138\n",
      "Epoch 20/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3261 - mse0: 1.0191 - mae0: 0.3313 - r2_score0: -0.0117 - val_loss: 0.3006 - val_mse0: 0.9335 - val_mae0: 0.3082 - val_r2_score0: -0.0136\n",
      "Epoch 21/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3259 - mse0: 1.0175 - mae0: 0.3310 - r2_score0: -0.0104 - val_loss: 0.3003 - val_mse0: 0.9316 - val_mae0: 0.3083 - val_r2_score0: -0.0113\n",
      "Epoch 22/200\n",
      "38328/38328 [==============================] - 8s 208us/step - loss: 0.3256 - mse0: 1.0158 - mae0: 0.3316 - r2_score0: -0.0076 - val_loss: 0.2997 - val_mse0: 0.9278 - val_mae0: 0.3088 - val_r2_score0: -0.0057\n",
      "Epoch 23/200\n",
      "38328/38328 [==============================] - 8s 208us/step - loss: 0.3252 - mse0: 1.0129 - mae0: 0.3318 - r2_score0: -0.0042 - val_loss: 0.2993 - val_mse0: 0.9249 - val_mae0: 0.3094 - val_r2_score0: -0.0015\n",
      "Epoch 24/200\n",
      "38328/38328 [==============================] - 8s 210us/step - loss: 0.3248 - mse0: 1.0096 - mae0: 0.3322 - r2_score0: -0.0012 - val_loss: 0.2992 - val_mse0: 0.9242 - val_mae0: 0.3091 - val_r2_score0: 9.2797e-05\n",
      "Epoch 25/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.3246 - mse0: 1.0079 - mae0: 0.3319 - r2_score0: 7.5459e-04 - val_loss: 0.2991 - val_mse0: 0.9235 - val_mae0: 0.3091 - val_r2_score0: 7.5493e-04\n",
      "Epoch 26/200\n",
      "38328/38328 [==============================] - 8s 213us/step - loss: 0.3248 - mse0: 1.0082 - mae0: 0.3321 - r2_score0: 0.0010 - val_loss: 0.2993 - val_mse0: 0.9245 - val_mae0: 0.3089 - val_r2_score0: -7.5505e-04\n",
      "Epoch 27/200\n",
      "38328/38328 [==============================] - 8s 217us/step - loss: 0.3245 - mse0: 1.0070 - mae0: 0.3315 - r2_score0: 0.0014 - val_loss: 0.2993 - val_mse0: 0.9208 - val_mae0: 0.3111 - val_r2_score0: 0.0037\n",
      "Epoch 28/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3245 - mse0: 1.0055 - mae0: 0.3321 - r2_score0: 0.0027 - val_loss: 0.2995 - val_mse0: 0.9255 - val_mae0: 0.3085 - val_r2_score0: -0.0025\n",
      "Epoch 29/200\n",
      "38328/38328 [==============================] - 8s 213us/step - loss: 0.3245 - mse0: 1.0082 - mae0: 0.3315 - r2_score0: 6.0202e-04 - val_loss: 0.2994 - val_mse0: 0.9237 - val_mae0: 0.3093 - val_r2_score0: -8.6410e-04\n",
      "Epoch 30/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.3244 - mse0: 1.0067 - mae0: 0.3317 - r2_score0: 7.6383e-04 - val_loss: 0.2994 - val_mse0: 0.9235 - val_mae0: 0.3096 - val_r2_score0: -4.7777e-04\n",
      "Epoch 31/200\n",
      "38328/38328 [==============================] - 8s 213us/step - loss: 0.3243 - mse0: 1.0053 - mae0: 0.3323 - r2_score0: 0.0026 - val_loss: 0.2995 - val_mse0: 0.9235 - val_mae0: 0.3093 - val_r2_score0: -7.9971e-04\n",
      "Epoch 32/200\n",
      "38328/38328 [==============================] - 8s 205us/step - loss: 0.3244 - mse0: 1.0071 - mae0: 0.3319 - r2_score0: 0.0021 - val_loss: 0.2996 - val_mse0: 0.9243 - val_mae0: 0.3092 - val_r2_score0: -0.0020\n",
      "Epoch 33/200\n",
      "38328/38328 [==============================] - 8s 214us/step - loss: 0.3244 - mse0: 1.0060 - mae0: 0.3318 - r2_score0: 0.0030 - val_loss: 0.2998 - val_mse0: 0.9246 - val_mae0: 0.3097 - val_r2_score0: -0.0025\n",
      "Epoch 34/200\n",
      "38328/38328 [==============================] - 8s 206us/step - loss: 0.3241 - mse0: 1.0037 - mae0: 0.3321 - r2_score0: 0.0049 - val_loss: 0.2997 - val_mse0: 0.9244 - val_mae0: 0.3096 - val_r2_score0: -0.0019\n",
      "Epoch 35/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3242 - mse0: 1.0043 - mae0: 0.3317 - r2_score0: 0.0026 - val_loss: 0.2993 - val_mse0: 0.9225 - val_mae0: 0.3097 - val_r2_score0: 7.8798e-04\n",
      "Epoch 36/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.3238 - mse0: 1.0015 - mae0: 0.3321 - r2_score0: 0.0067 - val_loss: 0.2998 - val_mse0: 0.9263 - val_mae0: 0.3088 - val_r2_score0: -0.0048\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38328/38328 [==============================] - 8s 210us/step - loss: 0.3240 - mse0: 1.0042 - mae0: 0.3314 - r2_score0: 0.0040 - val_loss: 0.3001 - val_mse0: 0.9252 - val_mae0: 0.3106 - val_r2_score0: -0.0042\n",
      "Epoch 38/200\n",
      "38328/38328 [==============================] - 8s 208us/step - loss: 0.3241 - mse0: 1.0044 - mae0: 0.3316 - r2_score0: 0.0051 - val_loss: 0.3003 - val_mse0: 0.9279 - val_mae0: 0.3093 - val_r2_score0: -0.0079\n",
      "Epoch 39/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3240 - mse0: 1.0031 - mae0: 0.3317 - r2_score0: 0.0044 - val_loss: 0.2998 - val_mse0: 0.9269 - val_mae0: 0.3089 - val_r2_score0: -0.0062\n",
      "Epoch 40/200\n",
      "38328/38328 [==============================] - 8s 204us/step - loss: 0.3239 - mse0: 1.0039 - mae0: 0.3315 - r2_score0: 0.0037 - val_loss: 0.2997 - val_mse0: 0.9244 - val_mae0: 0.3101 - val_r2_score0: -0.0022\n",
      "Epoch 41/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3237 - mse0: 1.0013 - mae0: 0.3317 - r2_score0: 0.0077 - val_loss: 0.2994 - val_mse0: 0.9233 - val_mae0: 0.3107 - val_r2_score0: -0.0010\n",
      "Epoch 42/200\n",
      "38328/38328 [==============================] - 8s 209us/step - loss: 0.3239 - mse0: 1.0011 - mae0: 0.3320 - r2_score0: 0.0079 - val_loss: 0.2992 - val_mse0: 0.9263 - val_mae0: 0.3079 - val_r2_score0: -0.0036- ETA: 2s - loss: 0.3268 - mse0: 1.0033 - m\n",
      "Epoch 43/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3237 - mse0: 1.0006 - mae0: 0.3316 - r2_score0: 0.0052 - val_loss: 0.2992 - val_mse0: 0.9250 - val_mae0: 0.3080 - val_r2_score0: -0.0024\n",
      "Epoch 44/200\n",
      "38328/38328 [==============================] - 8s 212us/step - loss: 0.3238 - mse0: 1.0026 - mae0: 0.3314 - r2_score0: 0.0064 - val_loss: 0.2989 - val_mse0: 0.9219 - val_mae0: 0.3082 - val_r2_score0: 0.0014\n",
      "Epoch 45/200\n",
      "38328/38328 [==============================] - 8s 209us/step - loss: 0.3235 - mse0: 0.9989 - mae0: 0.3317 - r2_score0: 0.0103 - val_loss: 0.2973 - val_mse0: 0.9110 - val_mae0: 0.3106 - val_r2_score0: 0.0159\n",
      "Epoch 46/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3235 - mse0: 0.9998 - mae0: 0.3316 - r2_score0: 0.0085 - val_loss: 0.2952 - val_mse0: 0.8990 - val_mae0: 0.3116 - val_r2_score0: 0.0296se0: - ETA: 0s - loss: 0.3219 - mse0: 1.0039 - mae0: 0.3301 - r2_score0:\n",
      "Epoch 47/200\n",
      "38328/38328 [==============================] - 8s 204us/step - loss: 0.3230 - mse0: 0.9960 - mae0: 0.3320 - r2_score0: 0.0122 - val_loss: 0.2947 - val_mse0: 0.8985 - val_mae0: 0.3113 - val_r2_score0: 0.0306\n",
      "Epoch 48/200\n",
      "38328/38328 [==============================] - 8s 209us/step - loss: 0.3225 - mse0: 0.9934 - mae0: 0.3315 - r2_score0: 0.0162 - val_loss: 0.3050 - val_mse0: 0.8866 - val_mae0: 0.3390 - val_r2_score0: 0.0339\n",
      "Epoch 49/200\n",
      "38328/38328 [==============================] - 8s 211us/step - loss: 0.3218 - mse0: 0.9883 - mae0: 0.3316 - r2_score0: 0.0214 - val_loss: 0.3380 - val_mse0: 0.9166 - val_mae0: 0.3936 - val_r2_score0: -0.0364\n",
      "Epoch 50/200\n",
      "38328/38328 [==============================] - 8s 206us/step - loss: 0.3216 - mse0: 0.9887 - mae0: 0.3316 - r2_score0: 0.0220 - val_loss: 0.3510 - val_mse0: 0.9236 - val_mae0: 0.4052 - val_r2_score0: -0.0555\n",
      "Epoch 51/200\n",
      "38328/38328 [==============================] - 8s 205us/step - loss: 0.3215 - mse0: 0.9862 - mae0: 0.3308 - r2_score0: 0.0241 - val_loss: 0.3226 - val_mse0: 0.8930 - val_mae0: 0.3646 - val_r2_score0: 0.0122\n",
      "Epoch 52/200\n",
      "38328/38328 [==============================] - 8s 210us/step - loss: 0.3208 - mse0: 0.9837 - mae0: 0.3308 - r2_score0: 0.0260 - val_loss: 0.3140 - val_mse0: 0.8758 - val_mae0: 0.3529 - val_r2_score0: 0.0373\n",
      "Epoch 53/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3201 - mse0: 0.9802 - mae0: 0.3304 - r2_score0: 0.0297 - val_loss: 0.3680 - val_mse0: 0.9301 - val_mae0: 0.4198 - val_r2_score0: -0.0810\n",
      "Epoch 54/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3177 - mse0: 0.9654 - mae0: 0.3297 - r2_score0: 0.0457 - val_loss: 0.4306 - val_mse0: 0.9517 - val_mae0: 0.5048 - val_r2_score0: -0.1868\n",
      "Epoch 55/200\n",
      "38328/38328 [==============================] - 7s 190us/step - loss: 0.3174 - mse0: 0.9630 - mae0: 0.3292 - r2_score0: 0.0496 - val_loss: 0.4201 - val_mse0: 0.9445 - val_mae0: 0.4934 - val_r2_score0: -0.1927\n",
      "Epoch 56/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3163 - mse0: 0.9564 - mae0: 0.3288 - r2_score0: 0.0565 - val_loss: 0.4354 - val_mse0: 0.9618 - val_mae0: 0.5022 - val_r2_score0: -0.2322\n",
      "Epoch 57/200\n",
      "38328/38328 [==============================] - 7s 191us/step - loss: 0.3153 - mse0: 0.9525 - mae0: 0.3287 - r2_score0: 0.0606 - val_loss: 0.3775 - val_mse0: 0.8749 - val_mae0: 0.4236 - val_r2_score0: -0.0521\n",
      "Epoch 58/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3136 - mse0: 0.9431 - mae0: 0.3272 - r2_score0: 0.0662 - val_loss: 0.3441 - val_mse0: 0.8360 - val_mae0: 0.3898 - val_r2_score0: 0.0032\n",
      "Epoch 59/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3127 - mse0: 0.9354 - mae0: 0.3274 - r2_score0: 0.0765 - val_loss: 0.4047 - val_mse0: 0.8988 - val_mae0: 0.4630 - val_r2_score0: -0.1242\n",
      "Epoch 60/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.3107 - mse0: 0.9240 - mae0: 0.3263 - r2_score0: 0.0836 - val_loss: 0.4382 - val_mse0: 0.9737 - val_mae0: 0.4914 - val_r2_score0: -0.3253\n",
      "Epoch 61/200\n",
      "38328/38328 [==============================] - 7s 190us/step - loss: 0.3093 - mse0: 0.9072 - mae0: 0.3261 - r2_score0: 0.1051 - val_loss: 0.4034 - val_mse0: 0.8561 - val_mae0: 0.4490 - val_r2_score0: -0.0517\n",
      "Epoch 62/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3092 - mse0: 0.9141 - mae0: 0.3251 - r2_score0: 0.0939 - val_loss: 0.4592 - val_mse0: 0.9765 - val_mae0: 0.5079 - val_r2_score0: -0.3206\n",
      "Epoch 63/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3082 - mse0: 0.9129 - mae0: 0.3243 - r2_score0: 0.0998 - val_loss: 0.4225 - val_mse0: 0.9235 - val_mae0: 0.4706 - val_r2_score0: -0.2063\n",
      "Epoch 64/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3064 - mse0: 0.9012 - mae0: 0.3233 - r2_score0: 0.1135 - val_loss: 0.3663 - val_mse0: 0.8619 - val_mae0: 0.4068 - val_r2_score0: -0.0548\n",
      "Epoch 65/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.3074 - mse0: 0.9030 - mae0: 0.3240 - r2_score0: 0.1049 - val_loss: 0.3733 - val_mse0: 0.8892 - val_mae0: 0.4145 - val_r2_score0: -0.1287\n",
      "Epoch 66/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3054 - mse0: 0.8887 - mae0: 0.3234 - r2_score0: 0.1269 - val_loss: 0.3557 - val_mse0: 0.8457 - val_mae0: 0.3967 - val_r2_score0: -0.0280\n",
      "Epoch 67/200\n",
      "38328/38328 [==============================] - 8s 200us/step - loss: 0.3061 - mse0: 0.8962 - mae0: 0.3236 - r2_score0: 0.1185 - val_loss: 0.3433 - val_mse0: 0.8205 - val_mae0: 0.3874 - val_r2_score0: 0.0175\n",
      "Epoch 68/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.3057 - mse0: 0.8900 - mae0: 0.3226 - r2_score0: 0.1192 - val_loss: 0.3599 - val_mse0: 0.8714 - val_mae0: 0.4008 - val_r2_score0: -0.0900\n",
      "Epoch 69/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3047 - mse0: 0.8891 - mae0: 0.3224 - r2_score0: 0.1252 - val_loss: 0.3662 - val_mse0: 0.8721 - val_mae0: 0.4031 - val_r2_score0: -0.0788\n",
      "Epoch 70/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3049 - mse0: 0.8853 - mae0: 0.3227 - r2_score0: 0.1238 - val_loss: 0.3334 - val_mse0: 0.8085 - val_mae0: 0.3689 - val_r2_score0: 0.0328\n",
      "Epoch 71/200\n",
      "38328/38328 [==============================] - 8s 207us/step - loss: 0.3032 - mse0: 0.8768 - mae0: 0.3217 - r2_score0: 0.1341 - val_loss: 0.3467 - val_mse0: 0.8296 - val_mae0: 0.3810 - val_r2_score0: 0.0037\n",
      "Epoch 72/200\n",
      "38328/38328 [==============================] - 7s 195us/step - loss: 0.3038 - mse0: 0.8853 - mae0: 0.3220 - r2_score0: 0.1311 - val_loss: 0.3914 - val_mse0: 0.9310 - val_mae0: 0.4303 - val_r2_score0: -0.1875\n",
      "Epoch 73/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3031 - mse0: 0.8799 - mae0: 0.3209 - r2_score0: 0.1359 - val_loss: 0.3544 - val_mse0: 0.8466 - val_mae0: 0.3914 - val_r2_score0: -0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3048 - mse0: 0.8888 - mae0: 0.3221 - r2_score0: 0.1246 - val_loss: 0.3389 - val_mse0: 0.8142 - val_mae0: 0.3770 - val_r2_score0: 0.0335\n",
      "Epoch 75/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3032 - mse0: 0.8807 - mae0: 0.3213 - r2_score0: 0.1355 - val_loss: 0.3775 - val_mse0: 0.9047 - val_mae0: 0.4173 - val_r2_score0: -0.1451\n",
      "Epoch 76/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.3039 - mse0: 0.8792 - mae0: 0.3216 - r2_score0: 0.1358 - val_loss: 0.3369 - val_mse0: 0.8138 - val_mae0: 0.3722 - val_r2_score0: 0.0231\n",
      "Epoch 77/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3028 - mse0: 0.8767 - mae0: 0.3207 - r2_score0: 0.1325 - val_loss: 0.3433 - val_mse0: 0.8406 - val_mae0: 0.3807 - val_r2_score0: -0.0175\n",
      "Epoch 78/200\n",
      "38328/38328 [==============================] - 7s 191us/step - loss: 0.3029 - mse0: 0.8717 - mae0: 0.3214 - r2_score0: 0.1402 - val_loss: 0.3687 - val_mse0: 0.8612 - val_mae0: 0.4120 - val_r2_score0: -0.1039\n",
      "Epoch 79/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3026 - mse0: 0.8770 - mae0: 0.3207 - r2_score0: 0.1357 - val_loss: 0.3763 - val_mse0: 0.8904 - val_mae0: 0.4129 - val_r2_score0: -0.1309\n",
      "Epoch 80/200\n",
      "38328/38328 [==============================] - 7s 191us/step - loss: 0.3013 - mse0: 0.8584 - mae0: 0.3200 - r2_score0: 0.1472 - val_loss: 0.3565 - val_mse0: 0.8431 - val_mae0: 0.3945 - val_r2_score0: -0.0595\n",
      "Epoch 81/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.3029 - mse0: 0.8718 - mae0: 0.3214 - r2_score0: 0.1447 - val_loss: 0.3351 - val_mse0: 0.8103 - val_mae0: 0.3745 - val_r2_score0: 0.0201 - mse0: 0.\n",
      "Epoch 82/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.3021 - mse0: 0.8718 - mae0: 0.3208 - r2_score0: 0.1409 - val_loss: 0.3454 - val_mse0: 0.8602 - val_mae0: 0.3814 - val_r2_score0: -0.0273\n",
      "Epoch 83/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.3005 - mse0: 0.8659 - mae0: 0.3193 - r2_score0: 0.1544 - val_loss: 0.3425 - val_mse0: 0.8404 - val_mae0: 0.3786 - val_r2_score0: 0.0027\n",
      "Epoch 84/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.3021 - mse0: 0.8738 - mae0: 0.3197 - r2_score0: 0.1394 - val_loss: 0.3241 - val_mse0: 0.8108 - val_mae0: 0.3572 - val_r2_score0: 0.0445\n",
      "Epoch 85/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.3020 - mse0: 0.8619 - mae0: 0.3211 - r2_score0: 0.1447 - val_loss: 0.3398 - val_mse0: 0.8136 - val_mae0: 0.3726 - val_r2_score0: 0.0293\n",
      "Epoch 86/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3017 - mse0: 0.8736 - mae0: 0.3199 - r2_score0: 0.1427 - val_loss: 0.3126 - val_mse0: 0.7910 - val_mae0: 0.3454 - val_r2_score0: 0.1016\n",
      "Epoch 87/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.3014 - mse0: 0.8698 - mae0: 0.3202 - r2_score0: 0.1340 - val_loss: 0.3262 - val_mse0: 0.8165 - val_mae0: 0.3580 - val_r2_score0: 0.0423\n",
      "Epoch 88/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.3007 - mse0: 0.8626 - mae0: 0.3199 - r2_score0: 0.1466 - val_loss: 0.3213 - val_mse0: 0.8006 - val_mae0: 0.3520 - val_r2_score0: 0.0669\n",
      "Epoch 89/200\n",
      "38328/38328 [==============================] - 8s 202us/step - loss: 0.3011 - mse0: 0.8648 - mae0: 0.3202 - r2_score0: 0.1472 - val_loss: 0.3449 - val_mse0: 0.8334 - val_mae0: 0.3808 - val_r2_score0: -0.0294\n",
      "Epoch 90/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3013 - mse0: 0.8664 - mae0: 0.3201 - r2_score0: 0.1439 - val_loss: 0.3334 - val_mse0: 0.8282 - val_mae0: 0.3669 - val_r2_score0: 0.0043\n",
      "Epoch 91/200\n",
      "38328/38328 [==============================] - 8s 196us/step - loss: 0.3005 - mse0: 0.8616 - mae0: 0.3200 - r2_score0: 0.1472 - val_loss: 0.3347 - val_mse0: 0.8463 - val_mae0: 0.3666 - val_r2_score0: -0.0212\n",
      "Epoch 92/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3020 - mse0: 0.8692 - mae0: 0.3200 - r2_score0: 0.1390 - val_loss: 0.3205 - val_mse0: 0.8121 - val_mae0: 0.3540 - val_r2_score0: 0.0659\n",
      "Epoch 93/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.3007 - mse0: 0.8642 - mae0: 0.3195 - r2_score0: 0.1491 - val_loss: 0.3172 - val_mse0: 0.7970 - val_mae0: 0.3509 - val_r2_score0: 0.0774\n",
      "Epoch 94/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.2991 - mse0: 0.8543 - mae0: 0.3185 - r2_score0: 0.1616 - val_loss: 0.3245 - val_mse0: 0.8197 - val_mae0: 0.3559 - val_r2_score0: 0.0335\n",
      "Epoch 95/200\n",
      "38328/38328 [==============================] - 8s 205us/step - loss: 0.3004 - mse0: 0.8577 - mae0: 0.3196 - r2_score0: 0.1589 - val_loss: 0.3265 - val_mse0: 0.8169 - val_mae0: 0.3595 - val_r2_score0: 0.0165\n",
      "Epoch 96/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.2997 - mse0: 0.8550 - mae0: 0.3191 - r2_score0: 0.1490 - val_loss: 0.3398 - val_mse0: 0.8407 - val_mae0: 0.3731 - val_r2_score0: -0.0221\n",
      "Epoch 97/200\n",
      "38328/38328 [==============================] - 8s 200us/step - loss: 0.3007 - mse0: 0.8614 - mae0: 0.3198 - r2_score0: 0.1463 - val_loss: 0.3368 - val_mse0: 0.8238 - val_mae0: 0.3722 - val_r2_score0: -0.0022\n",
      "Epoch 98/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.2999 - mse0: 0.8510 - mae0: 0.3194 - r2_score0: 0.1564 - val_loss: 0.3488 - val_mse0: 0.8785 - val_mae0: 0.3796 - val_r2_score0: -0.0837\n",
      "Epoch 99/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.2990 - mse0: 0.8465 - mae0: 0.3194 - r2_score0: 0.1614 - val_loss: 0.3119 - val_mse0: 0.7979 - val_mae0: 0.3445 - val_r2_score0: 0.0823\n",
      "Epoch 100/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.3000 - mse0: 0.8551 - mae0: 0.3195 - r2_score0: 0.1540 - val_loss: 0.3310 - val_mse0: 0.8308 - val_mae0: 0.3648 - val_r2_score0: 0.0090\n",
      "Epoch 101/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.2997 - mse0: 0.8512 - mae0: 0.3188 - r2_score0: 0.1556 - val_loss: 0.3152 - val_mse0: 0.8059 - val_mae0: 0.3474 - val_r2_score0: 0.0792\n",
      "Epoch 102/200\n",
      "38328/38328 [==============================] - 8s 196us/step - loss: 0.2981 - mse0: 0.8479 - mae0: 0.3182 - r2_score0: 0.1678 - val_loss: 0.3257 - val_mse0: 0.8282 - val_mae0: 0.3601 - val_r2_score0: 0.0092\n",
      "Epoch 103/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.2989 - mse0: 0.8514 - mae0: 0.3181 - r2_score0: 0.1629 - val_loss: 0.3244 - val_mse0: 0.8230 - val_mae0: 0.3568 - val_r2_score0: 0.0147\n",
      "Epoch 104/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.2984 - mse0: 0.8472 - mae0: 0.3185 - r2_score0: 0.1549 - val_loss: 0.3410 - val_mse0: 0.8621 - val_mae0: 0.3735 - val_r2_score0: -0.0454\n",
      "Epoch 105/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.2989 - mse0: 0.8501 - mae0: 0.3184 - r2_score0: 0.1639 - val_loss: 0.3449 - val_mse0: 0.8889 - val_mae0: 0.3747 - val_r2_score0: -0.0814\n",
      "Epoch 106/200\n",
      "38328/38328 [==============================] - 7s 192us/step - loss: 0.2982 - mse0: 0.8481 - mae0: 0.3182 - r2_score0: 0.1522 - val_loss: 0.3750 - val_mse0: 0.9349 - val_mae0: 0.4065 - val_r2_score0: -0.1979\n",
      "Epoch 107/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3000 - mse0: 0.8452 - mae0: 0.3192 - r2_score0: 0.1632 - val_loss: 0.3175 - val_mse0: 0.8025 - val_mae0: 0.3499 - val_r2_score0: 0.0664\n",
      "Epoch 108/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.2973 - mse0: 0.8471 - mae0: 0.3170 - r2_score0: 0.1642 - val_loss: 0.3572 - val_mse0: 0.9034 - val_mae0: 0.3860 - val_r2_score0: -0.1036\n",
      "Epoch 109/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.2973 - mse0: 0.8433 - mae0: 0.3173 - r2_score0: 0.1684 - val_loss: 0.3233 - val_mse0: 0.8269 - val_mae0: 0.3538 - val_r2_score0: 0.0082\n",
      "Epoch 110/200\n",
      "38328/38328 [==============================] - 7s 191us/step - loss: 0.2985 - mse0: 0.8449 - mae0: 0.3182 - r2_score0: 0.1656 - val_loss: 0.3167 - val_mse0: 0.7999 - val_mae0: 0.3476 - val_r2_score0: 0.0630\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.3006 - mse0: 0.8593 - mae0: 0.3198 - r2_score0: 0.1451 - val_loss: 0.3327 - val_mse0: 0.8176 - val_mae0: 0.3664 - val_r2_score0: 0.0314\n",
      "Epoch 112/200\n",
      "38328/38328 [==============================] - 7s 190us/step - loss: 0.2979 - mse0: 0.8440 - mae0: 0.3177 - r2_score0: 0.1660 - val_loss: 0.3077 - val_mse0: 0.7922 - val_mae0: 0.3368 - val_r2_score0: 0.0869\n",
      "Epoch 113/200\n",
      "38328/38328 [==============================] - 8s 196us/step - loss: 0.2993 - mse0: 0.8489 - mae0: 0.3188 - r2_score0: 0.1600 - val_loss: 0.3232 - val_mse0: 0.8465 - val_mae0: 0.3495 - val_r2_score0: 0.0234\n",
      "Epoch 114/200\n",
      "38328/38328 [==============================] - 7s 191us/step - loss: 0.2969 - mse0: 0.8374 - mae0: 0.3170 - r2_score0: 0.1693 - val_loss: 0.3034 - val_mse0: 0.7871 - val_mae0: 0.3326 - val_r2_score0: 0.0894\n",
      "Epoch 115/200\n",
      "38328/38328 [==============================] - 8s 196us/step - loss: 0.2958 - mse0: 0.8291 - mae0: 0.3158 - r2_score0: 0.1764 - val_loss: 0.3149 - val_mse0: 0.8183 - val_mae0: 0.3425 - val_r2_score0: 0.0430\n",
      "Epoch 116/200\n",
      "38328/38328 [==============================] - 7s 193us/step - loss: 0.2982 - mse0: 0.8378 - mae0: 0.3180 - r2_score0: 0.1708 - val_loss: 0.3250 - val_mse0: 0.8179 - val_mae0: 0.3564 - val_r2_score0: 0.0307\n",
      "Epoch 117/200\n",
      "38328/38328 [==============================] - 8s 199us/step - loss: 0.2974 - mse0: 0.8411 - mae0: 0.3174 - r2_score0: 0.1566 - val_loss: 0.3277 - val_mse0: 0.8295 - val_mae0: 0.3585 - val_r2_score0: 0.0196\n",
      "Epoch 118/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.2956 - mse0: 0.8340 - mae0: 0.3162 - r2_score0: 0.1692 - val_loss: 0.3322 - val_mse0: 0.8472 - val_mae0: 0.3633 - val_r2_score0: -0.0462\n",
      "Epoch 119/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.2985 - mse0: 0.8502 - mae0: 0.3177 - r2_score0: 0.1517 - val_loss: 0.3229 - val_mse0: 0.8187 - val_mae0: 0.3519 - val_r2_score0: 0.0314\n",
      "Epoch 120/200\n",
      "38328/38328 [==============================] - 7s 194us/step - loss: 0.2981 - mse0: 0.8460 - mae0: 0.3173 - r2_score0: 0.1632 - val_loss: 0.3068 - val_mse0: 0.7993 - val_mae0: 0.3366 - val_r2_score0: 0.0939\n",
      "Epoch 121/200\n",
      "38328/38328 [==============================] - 8s 201us/step - loss: 0.2986 - mse0: 0.8537 - mae0: 0.3186 - r2_score0: 0.1558 - val_loss: 0.3170 - val_mse0: 0.8058 - val_mae0: 0.3479 - val_r2_score0: 0.0744\n",
      "Epoch 122/200\n",
      "38328/38328 [==============================] - 8s 202us/step - loss: 0.2965 - mse0: 0.8422 - mae0: 0.3178 - r2_score0: 0.1681 - val_loss: 0.3239 - val_mse0: 0.8061 - val_mae0: 0.3566 - val_r2_score0: 0.0294\n",
      "Epoch 123/200\n",
      "38328/38328 [==============================] - 8s 198us/step - loss: 0.2954 - mse0: 0.8303 - mae0: 0.3157 - r2_score0: 0.1692 - val_loss: 0.3045 - val_mse0: 0.7852 - val_mae0: 0.3357 - val_r2_score0: 0.1130\n",
      "Epoch 124/200\n",
      "38328/38328 [==============================] - 7s 195us/step - loss: 0.2970 - mse0: 0.8347 - mae0: 0.3179 - r2_score0: 0.1713 - val_loss: 0.3046 - val_mse0: 0.7864 - val_mae0: 0.3365 - val_r2_score0: 0.0976\n",
      "Epoch 125/200\n",
      "38328/38328 [==============================] - 8s 203us/step - loss: 0.2988 - mse0: 0.8522 - mae0: 0.3180 - r2_score0: 0.1534 - val_loss: 0.3255 - val_mse0: 0.8482 - val_mae0: 0.3566 - val_r2_score0: -0.0175\n",
      "Epoch 126/200\n",
      "38328/38328 [==============================] - 8s 200us/step - loss: 0.2977 - mse0: 0.8375 - mae0: 0.3186 - r2_score0: 0.1678 - val_loss: 0.3137 - val_mse0: 0.8016 - val_mae0: 0.3442 - val_r2_score0: 0.0709\n",
      "Epoch 127/200\n",
      "38328/38328 [==============================] - 7s 195us/step - loss: 0.2960 - mse0: 0.8286 - mae0: 0.3172 - r2_score0: 0.1785 - val_loss: 0.3146 - val_mse0: 0.8167 - val_mae0: 0.3422 - val_r2_score0: 0.0600\n",
      "Epoch 128/200\n",
      "38328/38328 [==============================] - 8s 197us/step - loss: 0.2966 - mse0: 0.8368 - mae0: 0.3167 - r2_score0: 0.1749 - val_loss: 0.3281 - val_mse0: 0.8382 - val_mae0: 0.3594 - val_r2_score0: 0.0042\n",
      "Epoch 129/200\n",
      "32000/38328 [========================>.....] - ETA: 1s - loss: 0.2954 - mse0: 0.8267 - mae0: 0.3156 - r2_score0: 0.1625"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=256,shuffle=True,validation_data=(X_valid,y_valid),epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape,y_train.shape,X_valid.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_valid[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(y_pred[:,1]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( (y_valid[:10000] - y_pred[:10000,0])**2/y_pred[:10000,1]**2 ) .max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.fit(X_train,y_train,validation_data=(X_valid,y_valid),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)#,p0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred[:,0],bins=100,range=[-1,1],histtype='step');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred.shape\n",
    "_,bins,_ = plt.hist(y_pred[:,0]-y_valid[:,0],bins=100,range=[-1,1],histtype='step');\n",
    "plt.hist(y_valid[:,0],bins=bins,histtype='step');\n",
    "#plt.hist(np.sqrt(y_valid[:,0]*y_std+y_mean),bins=bins,histtype='step');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_full = y_valid[:,0]\n",
    "# plt.hist(y_pred_full,range=[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_valid = (y_valid[:,0] * y_std + y_mean)*np.sqrt(y0_valid)\n",
    "mass_pred = (y_pred[:,0] * y_std + y_mean)*np.sqrt(y0_valid)\n",
    "mass0_valid = np.sqrt(y0_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_valid = np.sqrt(y_valid[:,0] * y_std + y_mean + y0_valid)\n",
    "# mass_pred  = np.sqrt(y_pred[:,0] * y_std + y_mean + y0_valid)\n",
    "# mass0_valid = np.sqrt(y0_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred0 = X['recoJet2p5Mass20'] + X['recoJet2p5Mass21'] + 2.*X['recoJet2p5P0P1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_pred / mass_valid -1., range=[-1,1], bins=100, histtype='step',normed=True);\n",
    "plt.hist(mass0_valid / mass_valid -1., range=[-1,1], bins=100, histtype='step',normed=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. - (mass_pred / mass_valid).std() / (mass0_valid / mass_valid).std()\n",
    "\n",
    "# plt.scatter(y_valid,y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y_pred[:,0],np.abs(y_pred[:,1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y0_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
